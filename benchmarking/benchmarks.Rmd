---
title: "Benchmarks"
author: "Aris Paschalidis"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(coiaf)
library(McCOILR)
library(patchwork)
```

# Comparing coiaf methods

| Variant Method | Frequency Method |
| :------------: | :--------------: |
| Discrete       | Discrete         |
| Continuous     | Continuous       |

```{r function definitions}
# Set seed
# set.seed(101)

# Create function to take variable COI and # of loci
create_data <- function(coi, n_loci) {
  plmaf <- stats::rbeta(n_loci, 1, 5)
  plmaf[plmaf > 0.5] <- 1 - plmaf[plmaf > 0.5]

  sim_biallelic(coi = coi, plmaf = plmaf)
}
```

```{r bench fns, include = FALSE}
bench_plot <- function(bench, title = NULL) {
  bench <- dplyr::rename(bench, Loci = n_loci, COI = coi)

  ggplot2::autoplot(bench, show.legend = TRUE, alpha = 0.8) +
    theme_coiaf() +
    ggplot2::labs(y = "Time", x = "Estimation Method", title = title) +
    ggplot2::scale_color_discrete(
      name = "Garbage Collection",
      labels = c("None", "Level 0", "Level 1", "Level 2")
    ) +
    ggplot2::theme(legend.title = ggplot2::element_text(hjust = 0.5)) +
    ggplot2::guides(x = ggplot2::guide_axis(angle = 45))
}

bench_stats <- function(bench) {
  bench <- dplyr::rename(bench, Loci = n_loci, COI = coi)

  stats <- bench %>%
    dplyr::select(expression, COI, Loci, time) %>%
    dplyr::mutate(expression = as.character(expression)) %>% 
    dplyr::filter(COI != 1)

  if ("Discrete" %in% stats$expression) {
    discrete <- stats %>%
      dplyr::filter(expression == "Discrete") %>%
      dplyr::pull(time) %>% 
      unlist()

    continuous <- stats %>%
      dplyr::filter(expression != "Discrete") %>%
      dplyr::pull(time) %>% 
      unlist()

    pvalue <- wilcox.test(discrete, continuous, paired = TRUE)$p.value
    means <- c(discrete = mean(discrete), continuous = mean(continuous))
  } else if ("Variant" %in% stats$expression) {
    variant <- stats %>%
      dplyr::filter(expression == "Variant") %>%
      dplyr::pull(time) %>% 
      unlist()

    frequency <- stats %>%
      dplyr::filter(expression != "Variant") %>%
      dplyr::pull(time) %>% 
      unlist()

   pvalue <- wilcox.test(variant, frequency, paired = TRUE)$p.value
   means <- c(variant = mean(variant), frequency = mean(frequency))
  }
  
  c(format(means, scientific = FALSE), pvalue = pvalue)
}
```

```{r disc vs cont variant method}
bench_var <- bench::press(
  coi = c(1, seq(5, 25, 5)),
  n_loci = c(100, 1000, 5000, 10000),
  {
    dat <- create_data(coi, n_loci)
    bench::mark(
      min_iterations = 100,
      Discrete = compute_coi(dat, "sim"),
      Continuous = optimize_coi(dat, "sim"),
      check = FALSE
    )
  }
)

bench_plot(bench_var)
bench_stats(bench_var)
```

```{r disc vs cont freq method}
bench_freq <- bench::press(
  coi = c(1, seq(5, 25, 5)),
  n_loci = c(100, 1000, 5000, 10000),
  {
    dat <- create_data(coi, n_loci)
    bench::mark(
      min_iterations = 100,
      Discrete = compute_coi(dat, "sim", coi_method = "frequency"),
      Continuous = optimize_coi(dat, "sim", coi_method = "frequency"),
      check = FALSE
    )
  }
)

bench_plot(bench_freq)
bench_stats(bench_freq)
```

```{r combine discrete vs continuous plots}
bench_plot(bench_var) + bench_plot(bench_freq) +
  plot_layout(guides = "collect") +
  plot_annotation(
    tag_levels = "A",
    theme = theme(plot.tag = element_text(size = 10))
  ) &
  theme(plot.tag = element_text(face = "bold")) &
  theme(legend.position = "bottom")

ggsave(
  filename = here::here("benchmarking", "bench-images", "bench-soln-methods.png"),
  device = "png", 
  width = 2500, 
  height = 1500, 
  units = "px", 
  dpi = "print"
)
```


```{r var vs freq discrete}
bench_dis <- bench::press(
  coi = c(1, seq(5, 25, 5)),
  n_loci = c(100, 1000, 5000, 10000),
  {
    dat <- create_data(coi, n_loci)
    bench::mark(
      min_iterations = 100,
      Variant = compute_coi(dat, "sim", coi_method = "variant"),
      Frequency = compute_coi(dat, "sim", coi_method = "frequency"),
      check = FALSE
    )
  }
)

bench_plot(bench_dis)
bench_stats(bench_dis)
```

```{r var vs freq discrete}
bench_cont <- bench::press(
  coi = c(1, seq(5, 25, 5)),
  n_loci = c(100, 1000, 5000, 10000),
  {
    dat <- create_data(coi, n_loci)
    bench::mark(
      min_iterations = 100,
      Variant = optimize_coi(dat, "sim", coi_method = "variant"),
      Frequency = optimize_coi(dat, "sim", coi_method = "frequency"),
      check = FALSE
    )
  }
)

bench_plot(bench_cont)
bench_stats(bench_cont)
```

```{r combine discrete vs continuous plots}
bench_plot(bench_dis) + bench_plot(bench_cont) +
  plot_layout(guides = "collect") +
  plot_annotation(
    tag_levels = "A",
    theme = theme(plot.tag = element_text(size = 10))
  ) &
  theme(plot.tag = element_text(face = "bold")) &
  theme(legend.position = "bottom")

ggsave(
  filename = here::here("benchmarking", "bench-images", "bench-estim-methods.png"),
  device = "png", 
  width = 2500, 
  height = 1500, 
  units = "px", 
  dpi = "print"
)
```

From these results, we can see that for small numbers of loci, the discrete
method is almost twice as fast as the continuous method. However, as the number
of loci increases, this difference becomes smaller.

# coiaf vs RMCL

In order to compare THE REAL McCOIL to coiaf, we compare our base methods,
our bootstrapped methods, against THE REAL McCOIL. The benchmarking runs for 
this are outlined in separate file. Here we work on organizing and visualizing 
those results.

```{r import data}
# Extract all the files
files <- fs::dir_ls(here::here("benchmarking", "rmcl-coiaf-data")) %>%
  vctrs::vec_set_names(fs::path_file(.))

# Merge the data sets together
data <- purrr::map(files, readRDS) %>%
  dplyr::bind_rows(.id = "file") %>%
  dplyr::mutate(
    stringr::str_extract_all(file, "\\d+", simplify = TRUE) %>%
      tibble::as_tibble() %>%
      rlang::set_names(c("loci", "samples"))
  )
```

To plot the data, we can either plot the median run time over 10 iterations,
or create a boxplot.

```{r boxplot}
# Plot boxplot
data %>%
  dplyr::mutate(
    loci = forcats::fct(loci, levels = c("100", "500", "1000", "5000")),
    expression = as.character(expression)
  ) %>%
  tidyr::unnest(c(time, gc)) %>% 
  ggplot(plot_data, aes(x = loci, y = time, color = expression)) +
  geom_boxplot() +
  facet_wrap(~ samples, scales = "free_y") +
  coiaf::theme_coiaf()
```

```{r median run time}
# Plot median
data %>%
  dplyr::mutate(
    loci = as.numeric(loci),
    samples = ifelse(samples == 100, "100 Samples", "500 Samples"),
    expression = forcats::as_factor(as.character(expression)),
    expression = forcats::fct_recode(
      expression,
      "Bootstrapped coiaf" = "coiaf_boot",
      "Parallelized Bootstrapped coiaf" = "coiaf_boot_par",
      "Continuous coiaf" = "coiaf_cont",
      "Discrete coiaf" = "coiaf_disc",
      "THE REAL McCOIL" = "rmcl",
    )
  ) %>%
  ggplot(aes(x = loci, y = median, color = expression, group = expression)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ samples, scales = "free_y") +
  labs(x = "Number of Loci", y = "Median Run Time (s)", color = "") +
  coiaf::theme_coiaf() +
  theme(legend.position = "bottom")

ggsave(
  filename = here::here("benchmarking", "bench-images", "rmcl-vs-coiaf.png"),
  device = "png", 
  width = 2500, 
  height = 1500, 
  units = "px", 
  dpi = "print"
)
```

## Confidence interval comparison

We note that for a fair comparison of our bootstrapped methods and THE REAL
McCOIL, it is important to illustrate that the confidence intervals between the
two software packages are comparable.

```{r simulate data}
withr::local_seed(211)

# Setup inputs
n_coi <- rep(seq(2, 10, 2), 10)
n_coi <- rlang::set_names(n_coi, ~ paste0("sample_", seq_along(.)))
plmaf <- runif(1000, 0, 0.5)
seq_error <- 0

# Simulate data
sim_data <- purrr::map(
  n_coi,
  coiaf::sim_biallelic,
  plmaf = plmaf,
  coverage = 200,
)

# Compute genotypes
genotypes <- purrr::map(sim_data, function(x) {
    gtmat <- x$data$wsmaf
    gtmat[gtmat >= (1 - seq_error)] <- 1
    gtmat[gtmat <= seq_error] <- 0
    gtmat[gtmat > seq_error & gtmat < (1 - seq_error)] <- 0.5
    gtmat
  })

# Get genotype matrix to feed into RMCL
gtmat <- do.call(rbind, genotypes)
colnames(gtmat) <- paste0("pos_", seq_len(ncol(gtmat)))
gtmat <- as.data.frame(gtmat)
```

We can the run the algorithm with 5,000 iterations and a burn-in period of 2,000â€”the reasoning for why we use these values is described in another file.

```{r run software}
# Run coiaf
coiaf <- purrr::map(sim_data, coiaf::bootstrap_ci, parallel = FALSE) %>% 
  purrr::list_rbind()

# Run THE REAL McCOIL
rmcl <- McCOIL_categorical(
  data = gtmat,
  maxCOI = 25,
  totalrun = 5000,
  burnin = 2000,
  M0 = 5,
  err_method = 3,
  path = tempdir(),
)
```

The last step is to extract the COI estimates.

```{r extract output}
coiaf_density <- coiaf %>% 
  tidyr::unnest_longer(estimates) %>% 
  select(estimates)

# Extract output
chains <- read.table(paste0(tempdir(), "/output.txt"))
chains_coi <- chains %>% 
  dplyr::slice_tail(n = -2) %>%
  dplyr::select(2:6) %>% 
  tidyr::pivot_longer(everything(), names_to = "sim_coi", values_to = "estimates") %>% 
  dplyr::mutate(
    sim_coi = forcats::as_factor(sim_coi),
    sim_coi = forcats::fct_recode(
      sim_coi, "2" = "V2", "4" = "V3", "6" = "V4", "8" = "V5", "10" = "V6"
    )
  ) %>% 
  dplyr::filter(estimates < 100)
```

```{r plot estimates}
# Merge data
dens_data <- bind_rows(
  list(coiaf = coi_density, "THE REAL McCOIL" = chains_coi), 
  .id = "software"
) %>% 
  mutate(sim_coi = forcats::as_factor(paste0("COI = ", n_coi)))

# Plot
ggplot(dens_data, aes(x = estimates, group = software, fill = software)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ sim_coi, nrow = 1, scales = "free") +
  labs(x = "Estimated COI", y = "Density", fill = "Software") +
  theme_coiaf() +
  theme(legend.position = "bottom")

ggsave(
  filename = here::here("benchmarking", "bootstrapping-coi-density.png"),
  device = "png", 
  width = 2000, 
  height = 1750, 
  units = "px", 
  dpi = "print"
)
```
